{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f91ea02",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 3.891508,
     "end_time": "2024-09-22T08:45:24.453891",
     "exception": false,
     "start_time": "2024-09-22T08:45:20.562383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset\\fake\\id0_id1_0000.mp4\n",
      "dataset\\fake\\id0_id1_0001.mp4\n",
      "dataset\\fake\\id0_id1_0002.mp4\n",
      "dataset\\fake\\id0_id1_0003.mp4\n",
      "dataset\\fake\\id0_id1_0005.mp4\n",
      "dataset\\fake\\id0_id1_0006.mp4\n",
      "dataset\\fake\\id0_id1_0007.mp4\n",
      "dataset\\fake\\id0_id1_0009.mp4\n",
      "dataset\\fake\\id0_id2_0000.mp4\n",
      "dataset\\fake\\id0_id2_0001.mp4\n",
      "dataset\\fake\\id0_id2_0002.mp4\n",
      "dataset\\fake\\id0_id2_0003.mp4\n",
      "dataset\\fake\\id0_id2_0004.mp4\n",
      "dataset\\fake\\id0_id2_0005.mp4\n",
      "dataset\\fake\\id0_id2_0006.mp4\n",
      "dataset\\real\\id0_0000.mp4\n",
      "dataset\\real\\id0_0001.mp4\n",
      "dataset\\real\\id0_0002.mp4\n",
      "dataset\\real\\id0_0003.mp4\n",
      "dataset\\real\\id0_0004.mp4\n",
      "dataset\\real\\id0_0005.mp4\n",
      "dataset\\real\\id0_0006.mp4\n",
      "dataset\\real\\id0_0007.mp4\n",
      "dataset\\real\\id0_0008.mp4\n",
      "dataset\\real\\id0_0009.mp4\n",
      "dataset\\real\\id1_0000.mp4\n",
      "dataset\\real\\id1_0001.mp4\n",
      "dataset\\real\\id1_0002.mp4\n",
      "dataset\\real\\id1_0003.mp4\n",
      "dataset\\real\\id1_0004.mp4\n",
      "dataset\\real\\id1_0005.mp4\n",
      "dataset\\real\\id1_0006.mp4\n",
      "dataset\\real\\id1_0007.mp4\n",
      "dataset\\real\\id1_0008.mp4\n",
      "dataset\\real\\id1_0009.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('dataset'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8986723c",
   "metadata": {
    "papermill": {
     "duration": 27.608695,
     "end_time": "2024-09-22T08:45:52.081195",
     "exception": false,
     "start_time": "2024-09-22T08:45:24.472500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\2024\\NOVEMBER\\DeepFake\\align\\align_trans.py:279: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if align_type is 'cv2_affine':\n",
      "D:\\2024\\NOVEMBER\\DeepFake\\align\\align_trans.py:282: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif align_type is 'affine':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import numpy as np\n",
    "from align.align_trans import (\n",
    "    get_reference_facial_points,\n",
    "    warp_and_crop_face,\n",
    ")\n",
    "from align.detector import detect_faces\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0641b9a0",
   "metadata": {
    "papermill": {
     "duration": 0.046783,
     "end_time": "2024-09-22T08:45:52.141417",
     "exception": false,
     "start_time": "2024-09-22T08:45:52.094634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 real videos and 15 fake videos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define correct paths from the output of os.walk\n",
    "dataset_dir = 'dataset'\n",
    "\n",
    "real_videos_path = os.path.join(dataset_dir, 'real') \n",
    "fake_videos_path = os.path.join(dataset_dir, 'fake')  \n",
    "\n",
    "\n",
    "real_videos = [os.path.join(real_videos_path, video) for video in os.listdir(real_videos_path)]\n",
    "fake_videos = [os.path.join(fake_videos_path, video) for video in os.listdir(fake_videos_path)]\n",
    "\n",
    "\n",
    "video_paths = real_videos + fake_videos\n",
    "labels = [0] * len(real_videos) + [1] * len(fake_videos)\n",
    "\n",
    "df = pd.DataFrame({'video_path': video_paths, 'label': labels})\n",
    "\n",
    "print(f\"Found {len(real_videos)} real videos and {len(fake_videos)} fake videos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4cd0fb1-aa52-4bcc-90e5-66b579bf245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset\\real\\id0_0000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset\\real\\id0_0001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset\\real\\id0_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset\\real\\id0_0003.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset\\real\\id0_0004.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataset\\real\\id0_0005.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dataset\\real\\id0_0006.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dataset\\real\\id0_0007.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dataset\\real\\id0_0008.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dataset\\real\\id0_0009.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dataset\\real\\id1_0000.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dataset\\real\\id1_0001.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dataset\\real\\id1_0002.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dataset\\real\\id1_0003.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dataset\\real\\id1_0004.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dataset\\real\\id1_0005.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dataset\\real\\id1_0006.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dataset\\real\\id1_0007.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dataset\\real\\id1_0008.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dataset\\real\\id1_0009.mp4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dataset\\fake\\id0_id1_0000.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dataset\\fake\\id0_id1_0001.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dataset\\fake\\id0_id1_0002.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dataset\\fake\\id0_id1_0003.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dataset\\fake\\id0_id1_0005.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dataset\\fake\\id0_id1_0006.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dataset\\fake\\id0_id1_0007.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dataset\\fake\\id0_id1_0009.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dataset\\fake\\id0_id2_0000.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dataset\\fake\\id0_id2_0001.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>dataset\\fake\\id0_id2_0002.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>dataset\\fake\\id0_id2_0003.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dataset\\fake\\id0_id2_0004.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>dataset\\fake\\id0_id2_0005.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>dataset\\fake\\id0_id2_0006.mp4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       video_path  label\n",
       "0       dataset\\real\\id0_0000.mp4      0\n",
       "1       dataset\\real\\id0_0001.mp4      0\n",
       "2       dataset\\real\\id0_0002.mp4      0\n",
       "3       dataset\\real\\id0_0003.mp4      0\n",
       "4       dataset\\real\\id0_0004.mp4      0\n",
       "5       dataset\\real\\id0_0005.mp4      0\n",
       "6       dataset\\real\\id0_0006.mp4      0\n",
       "7       dataset\\real\\id0_0007.mp4      0\n",
       "8       dataset\\real\\id0_0008.mp4      0\n",
       "9       dataset\\real\\id0_0009.mp4      0\n",
       "10      dataset\\real\\id1_0000.mp4      0\n",
       "11      dataset\\real\\id1_0001.mp4      0\n",
       "12      dataset\\real\\id1_0002.mp4      0\n",
       "13      dataset\\real\\id1_0003.mp4      0\n",
       "14      dataset\\real\\id1_0004.mp4      0\n",
       "15      dataset\\real\\id1_0005.mp4      0\n",
       "16      dataset\\real\\id1_0006.mp4      0\n",
       "17      dataset\\real\\id1_0007.mp4      0\n",
       "18      dataset\\real\\id1_0008.mp4      0\n",
       "19      dataset\\real\\id1_0009.mp4      0\n",
       "20  dataset\\fake\\id0_id1_0000.mp4      1\n",
       "21  dataset\\fake\\id0_id1_0001.mp4      1\n",
       "22  dataset\\fake\\id0_id1_0002.mp4      1\n",
       "23  dataset\\fake\\id0_id1_0003.mp4      1\n",
       "24  dataset\\fake\\id0_id1_0005.mp4      1\n",
       "25  dataset\\fake\\id0_id1_0006.mp4      1\n",
       "26  dataset\\fake\\id0_id1_0007.mp4      1\n",
       "27  dataset\\fake\\id0_id1_0009.mp4      1\n",
       "28  dataset\\fake\\id0_id2_0000.mp4      1\n",
       "29  dataset\\fake\\id0_id2_0001.mp4      1\n",
       "30  dataset\\fake\\id0_id2_0002.mp4      1\n",
       "31  dataset\\fake\\id0_id2_0003.mp4      1\n",
       "32  dataset\\fake\\id0_id2_0004.mp4      1\n",
       "33  dataset\\fake\\id0_id2_0005.mp4      1\n",
       "34  dataset\\fake\\id0_id2_0006.mp4      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84654138",
   "metadata": {
    "papermill": {
     "duration": 0.033526,
     "end_time": "2024-09-22T08:45:52.187747",
     "exception": false,
     "start_time": "2024-09-22T08:45:52.154221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df, test_df \u001b[38;5;241m=\u001b[39m train_test_split(df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      2\u001b[0m train_df, val_df \u001b[38;5;241m=\u001b[39m train_test_split(train_df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Testing samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}, Validation samples: {len(val_df)}, Testing samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5758ba3-6f47-4ec8-91d3-dffcbf981d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f44ed7bd",
   "metadata": {
    "papermill": {
     "duration": 0.122313,
     "end_time": "2024-09-22T08:45:52.323132",
     "exception": false,
     "start_time": "2024-09-22T08:45:52.200819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_frames(video_path, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    count = 0\n",
    "    while cap.isOpened() and count < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (224, 224))  # Resize to 224x224\n",
    "        frames.append(frame)\n",
    "        count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def preprocess(imgname,filename):\n",
    "    \n",
    "    crop_size = 112\n",
    "    scale = crop_size / 112.0\n",
    "    reference = get_reference_facial_points(default_square=True) * scale\n",
    "    img = Image.open(imgname)\n",
    "    try: \n",
    "                    _, landmarks = detect_faces(img)\n",
    "                    facial5points = [[landmarks[0][j], landmarks[0][j + 5]] for j in range(5)]\n",
    "                    warped_face = warp_and_crop_face(\n",
    "                        np.array(img),\n",
    "                        facial5points,\n",
    "                        reference,\n",
    "                        crop_size=(crop_size, crop_size),\n",
    "                    )\n",
    "                    img_warped = Image.fromarray(warped_face)\n",
    "                    \n",
    "                    img_warped.save(filename)\n",
    "    except Exception:\n",
    "                    print(\n",
    "                        \"{} is discarded due to exception!\".format(\n",
    "                          Exception),\n",
    "                        )\n",
    "                    \n",
    "               \n",
    "                \n",
    "count=0\n",
    "\n",
    "for i in range(len(df.values.tolist())):\n",
    "    video_frames = extract_frames(df['video_path'].iloc[i])\n",
    "    labelname=\"real\"\n",
    "    if(df['label'].iloc[i]==1):\n",
    "        labelname=\"fake\"\n",
    "    for frame in video_frames:\n",
    "        count=count+1\n",
    "        filepath=\"preprocess/\"+labelname+\"/\"+str(count)+\".jpg\"\n",
    "        cv2.imwrite(\"1.jpg\", frame)\n",
    "        preprocess(\"1.jpg\",filepath)\n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3120670,
     "sourceId": 5380830,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5303.136707,
   "end_time": "2024-09-22T10:13:41.079248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-22T08:45:17.942541",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
